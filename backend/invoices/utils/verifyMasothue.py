from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from invoices.models import CompanyVerification, Company
from rapidfuzz import fuzz
import unicodedata
import re
import time


def normalize_text(text):
    if not text:
        return ""
    text = unicodedata.normalize("NFD", text)
    text = text.encode("ascii", "ignore").decode("utf-8")
    text = text.lower()

    # Thay tháº¿ tá»« viáº¿t táº¯t phá»• biáº¿n
    replacements = {
        "kcn": "khu cong nghiep",
        "tp": "thanh pho",
        "tp.": "thanh pho",
        "tp ho chi minh": "thanh pho ho chi minh",
        "hcmc": "thanh pho ho chi minh",
        "vn": "viet nam"
    }
    for k, v in replacements.items():
        text = re.sub(rf"\b{k}\b", v, text)

    text = re.sub(r"\s+", " ", text).strip()
    return text


def clean_company_name(name):
    """Loáº¡i cÃ¡c cá»¥m khÃ´ng cáº§n thiáº¿t, normalize Ä‘Æ¡n giáº£n"""
    name = name.lower()
    name = unicodedata.normalize("NFD", name)
    name = ''.join(c for c in name if unicodedata.category(c) != 'Mn')  # Bá» dáº¥u
    name = re.sub(r"[^a-z0-9\s\-]", " ", name)  # Bá» kÃ½ tá»± Ä‘áº·c biá»‡t nhÆ° ()
    name = re.sub(r"\b(cong|ty|co|phan|tnhh|mtv|trach|nhiem|huu|han|limited|ltd|international)\b", "", name)
    name = re.sub(r"\s+", " ", name).strip()
    return name

def is_similar(a, b):
    a_clean = clean_company_name(a)
    b_clean = clean_company_name(b)
    score = fuzz.token_set_ratio(a_clean, b_clean)
    return score >= 80 or a_clean in b_clean or b_clean in a_clean



def is_active_status(status_text):
    """XÃ¡c Ä‘á»‹nh tráº¡ng thÃ¡i hoáº¡t Ä‘á»™ng tá»« text OCR cÃ³ thá»ƒ sai"""
    status_text = normalize_text(status_text)
    active_keywords = [
        "hoat dong",
        "dang hoat dong",
        "ang hoat ong",
        "cap gcn",
        "chua ngung"
    ]
    return any(kw in status_text for kw in active_keywords)


def crawl_taxcode_data(tax_code):
    url = "https://masothue.com/"

    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("user-agent=Mozilla/5.0 ...")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        driver.get(url)
        time.sleep(2)

        driver.maximize_window()
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//*[@id="search"]'))
        )
        search_box.clear()
        search_box.send_keys(tax_code)

        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(5)

        name = driver.find_element(
            By.XPATH, '//*[@id="main"]/section[1]/div/table[1]/tbody/tr[2]/td[2]/span'
        ).text.strip()

        try:
            address = driver.find_element(
                By.XPATH, '//*[@id="main"]/section[1]/div/table[1]/tbody/tr[4]/td[2]/span'
            ).text.strip()
        except:
            address = ""

        try:
            status_text = driver.find_element(
                By.XPATH, '//*[@id="main"]/section[1]/div/table[1]/tbody/tr[10]/td[2]/a'
            ).text.strip()
        except:
            status_text = ""

        return {
            "name": name,
            "address": address,
            "status": status_text,
        }

    except Exception as e:
        print(f"âŒ Lá»—i crawl MST: {e}")
        return None

    finally:
        driver.quit()


def verify_company_data(company, crawled_data):
    if not crawled_data:
        return "FAIL", "KhÃ´ng crawl Ä‘Æ°á»£c dá»¯ liá»‡u"

    msg = []

    company_name = normalize_text(company.name)
    crawled_name = normalize_text(crawled_data.get("name", ""))

    cleaned_company_name = clean_company_name(company_name)
    cleaned_crawled_name = clean_company_name(crawled_name)

    if is_similar(cleaned_company_name, cleaned_crawled_name):
        msg.append("TÃªn trÃ¹ng khá»›p")
    else:
        msg.append("TÃªn KHÃ”NG khá»›p")

    company_address = normalize_text(company.address)
    crawled_address = normalize_text(crawled_data.get("address", ""))

    if is_similar(company_address, crawled_address):
        msg.append("Äá»‹a chá»‰ trÃ¹ng khá»›p")
    else:
        msg.append("Äá»‹a chá»‰ KHÃ”NG khá»›p")

    crawled_status = crawled_data.get("status", "")
    if is_active_status(crawled_status):
        msg.append("Tráº¡ng thÃ¡i Ä‘ang hoáº¡t Ä‘á»™ng")
    else:
        msg.append("Tráº¡ng thÃ¡i KHÃ”NG hoáº¡t Ä‘á»™ng")

    # Debug log
    print("ğŸ“Œ Company name:", company_name)
    print("ğŸ“Œ Crawled name:", crawled_name)
    print("ğŸ“Œ Company addr:", company_address)
    print("ğŸ“Œ Crawled addr:", crawled_address)
    print("ğŸ“Œ Status:", crawled_status)

    verify_status = "PASS" if all("KHÃ”NG" not in m for m in msg) else "FAIL"
    return verify_status, "; ".join(msg)
